# -*- coding: utf-8 -*-
"""
–í–µ–±-–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–π —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏
Flask-based –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –º–µ–Ω–µ–¥–∂–µ—Ä–æ–≤
"""

import os
import sys
import uuid
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any

from flask import Flask, render_template, request, jsonify, send_file, redirect, url_for
from flask_cors import CORS
from werkzeug.utils import secure_filename

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ src
sys.path.insert(0, str(Path(__file__).parent))

from config import APP_CONFIG, DATA_DIR, OUTPUT_DIR, TRADEMARK_RESOURCES, IMAGE_SEARCH_RESOURCES, MKTU_CLASSES
from models import ProductItem, CheckSession, ImageSource, RiskLevel
from data_loader import DataLoader, TemplateGenerator
from trademark_checker import ComprehensiveTrademarkChecker
from image_checker import ComprehensiveImageChecker
from image_search_api import ComprehensiveImageSearcher
from risk_evaluator import RiskEvaluator, RiskAssessment
from export_manager import ExportManager
from database import (
    save_name_check, save_image_check,
    get_name_checks, get_image_checks,
    get_name_check_by_id, get_image_check_by_id,
    get_statistics, delete_check, clear_history
)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Flask
app = Flask(__name__,
            template_folder=str(Path(__file__).parent.parent / 'templates'),
            static_folder=str(Path(__file__).parent.parent / 'static'))
app.config['SECRET_KEY'] = os.urandom(24).hex()
app.config['MAX_CONTENT_LENGTH'] = APP_CONFIG['max_file_size_mb'] * 1024 * 1024
app.config['UPLOAD_FOLDER'] = str(DATA_DIR / 'uploads')
CORS(app)

# –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –∑–∞–≥—Ä—É–∑–æ–∫
Path(app.config['UPLOAD_FOLDER']).mkdir(parents=True, exist_ok=True)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
data_loader = DataLoader()
trademark_checker = ComprehensiveTrademarkChecker()
image_checker = ComprehensiveImageChecker()
image_searcher = ComprehensiveImageSearcher()  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
risk_evaluator = RiskEvaluator()
export_manager = ExportManager()

# –•—Ä–∞–Ω–∏–ª–∏—â–µ —Å–µ—Å—Å–∏–π (–≤ production –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ë–î)
sessions_store: Dict[str, Dict] = {}


def allowed_file(filename: str, allowed_extensions: set) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ–ø—É—Å—Ç–∏–º–æ—Å—Ç–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ–∞–π–ª–∞"""
    return '.' in filename and \
           '.' + filename.rsplit('.', 1)[1].lower() in allowed_extensions


@app.route('/')
def index():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞"""
    return render_template('index.html',
                          mktu_classes=MKTU_CLASSES,
                          trademark_resources=TRADEMARK_RESOURCES,
                          image_resources=IMAGE_SEARCH_RESOURCES)


@app.route('/api/upload/excel', methods=['POST'])
def upload_excel():
    """–ó–∞–≥—Ä—É–∑–∫–∞ Excel/CSV —Ñ–∞–π–ª–∞ —Å —Ç–æ–≤–∞—Ä–∞–º–∏"""
    if 'file' not in request.files:
        return jsonify({'error': '–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω'}), 400

    file = request.files['file']
    if file.filename == '':
        return jsonify({'error': '–§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω'}), 400

    if not allowed_file(file.filename, APP_CONFIG['allowed_data_extensions']):
        return jsonify({'error': '–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞'}), 400

    try:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
        filename = secure_filename(file.filename)
        filepath = Path(app.config['UPLOAD_FOLDER']) / filename
        file.save(filepath)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        items = data_loader.load_from_excel(str(filepath))

        # –°–æ–∑–¥–∞–µ–º —Å–µ—Å—Å–∏—é
        session = data_loader.create_check_session(items)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
        sessions_store[session.session_id] = {
            'session': session,
            'assessments': {},
            'created_at': datetime.now().isoformat()
        }

        return jsonify({
            'success': True,
            'session_id': session.session_id,
            'total_items': len(items),
            'items': [
                {
                    'article': item.article,
                    'name': item.name,
                    'category': item.category,
                    'mktu_classes': item.mktu_classes,
                    'image_count': len(item.image_paths),
                    'text_on_product': item.text_on_product,
                    'source_type': item.image_source.source_type if item.image_source else 'unknown'
                }
                for item in items
            ]
        })

    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/upload/images', methods=['POST'])
def upload_images():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–∑ –ø–∞–ø–∫–∏ –∏–ª–∏ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
    if 'files' not in request.files:
        return jsonify({'error': '–§–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã'}), 400

    files = request.files.getlist('files')
    if not files:
        return jsonify({'error': '–§–∞–π–ª—ã –Ω–µ –≤—ã–±—Ä–∞–Ω—ã'}), 400

    try:
        items = []
        upload_dir = Path(app.config['UPLOAD_FOLDER']) / str(uuid.uuid4())[:8]
        upload_dir.mkdir(parents=True, exist_ok=True)

        for file in files:
            if file and allowed_file(file.filename, APP_CONFIG['allowed_extensions']):
                filename = secure_filename(file.filename)
                filepath = upload_dir / filename
                file.save(filepath)

                # –°–æ–∑–¥–∞–µ–º ProductItem –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                article = Path(filename).stem
                item = ProductItem(
                    article=article,
                    name=f"–¢–æ–≤–∞—Ä {article}",
                    image_paths=[str(filepath)],
                    image_source=ImageSource(source_type='unknown')
                )
                items.append(item)

        if not items:
            return jsonify({'error': '–ù–µ—Ç –¥–æ–ø—É—Å—Ç–∏–º—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π'}), 400

        # –°–æ–∑–¥–∞–µ–º —Å–µ—Å—Å–∏—é
        session = data_loader.create_check_session(items)

        sessions_store[session.session_id] = {
            'session': session,
            'assessments': {},
            'created_at': datetime.now().isoformat()
        }

        return jsonify({
            'success': True,
            'session_id': session.session_id,
            'total_items': len(items),
            'items': [
                {
                    'article': item.article,
                    'name': item.name,
                    'image_path': item.image_paths[0] if item.image_paths else None
                }
                for item in items
            ]
        })

    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/check/single', methods=['POST'])
def check_single():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–¥–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞"""
    data = request.json

    if not data:
        return jsonify({'error': '–î–∞–Ω–Ω—ã–µ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã'}), 400

    try:
        article = data.get('article', 'MANUAL_' + str(uuid.uuid4())[:8])
        text_to_check = data.get('text', '')
        mktu_classes = data.get('mktu_classes', [])
        image_path = data.get('image_path')

        results = {
            'article': article,
            'trademark_results': [],
            'image_results': None,
            'overall_status': 'green',
            'recommendations': [],
            'manual_check_links': {}
        }

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–≤–∞—Ä–Ω—ã—Ö –∑–Ω–∞–∫–æ–≤
        if text_to_check:
            tm_results = trademark_checker.check_all(text_to_check, mktu_classes)
            results['trademark_results'] = [
                {
                    'resource': r.resource_name,
                    'status': r.status.value,
                    'exact_match': r.exact_match,
                    'similar_match': r.similar_match,
                    'similarity_score': r.similarity_score,
                    'notes': r.notes,
                    'matches': r.found_matches[:15]  # –î–æ 15 —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
                }
                for r in tm_results
            ]

            # –°—Å—ã–ª–∫–∏ –¥–ª—è —Ä—É—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
            results['manual_check_links'] = trademark_checker.generate_manual_check_links(
                text_to_check, mktu_classes
            )

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        if image_path and os.path.exists(image_path):
            img_results = image_checker.check_image(image_path)
            results['image_results'] = {
                'recognized_texts': [
                    {'text': t.text, 'confidence': t.confidence}
                    for t in img_results.get('recognized_texts', [])
                ],
                'overall_status': img_results.get('overall_status', RiskLevel.GREEN).value,
                'recommendations': img_results.get('recommendations', [])
            }

            # –î–æ–±–∞–≤–ª—è–µ–º —Å—Å—ã–ª–∫–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            results['manual_check_links'].update(
                img_results.get('manual_check_links', {})
            )

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—â–∏–π —Å—Ç–∞—Ç—É—Å
        has_red = any(r['status'] == 'red' for r in results['trademark_results'])
        has_yellow = any(r['status'] == 'yellow' for r in results['trademark_results'])

        if results.get('image_results'):
            if results['image_results']['overall_status'] == 'red':
                has_red = True
            elif results['image_results']['overall_status'] == 'yellow':
                has_yellow = True

        if has_red:
            results['overall_status'] = 'red'
        elif has_yellow:
            results['overall_status'] = 'yellow'

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
        try:
            check_id = save_name_check(
                query_text=text_to_check,
                mktu_classes=mktu_classes,
                overall_status=results['overall_status'],
                results=results['trademark_results'],
                manual_links=results['manual_check_links']
            )
            results['check_id'] = check_id
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –∏—Å—Ç–æ—Ä–∏—é: {e}")

        return jsonify(results)

    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/check/session/<session_id>', methods=['POST'])
def check_session(session_id):
    """–ó–∞–ø—É—Å–∫ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–ª—è –≤—Å–µ–π —Å–µ—Å—Å–∏–∏"""
    if session_id not in sessions_store:
        return jsonify({'error': '–°–µ—Å—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'}), 404

    try:
        session_data = sessions_store[session_id]
        session = session_data['session']
        assessments = {}

        for item in session.items:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–≤–∞—Ä–Ω—ã—Ö –∑–Ω–∞–∫–æ–≤ –¥–ª—è —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Ç–æ–≤–∞—Ä–µ
            all_texts = item.text_on_product + item.logos_on_product
            for text in all_texts:
                if text:
                    tm_results = trademark_checker.check_all(text, item.mktu_classes)
                    item.trademark_results.extend(tm_results)

            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
            for image_path in item.image_paths:
                if os.path.exists(image_path):
                    img_check = image_checker.check_image(image_path)

                    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
                    item.recognized_texts.extend(img_check.get('recognized_texts', []))

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–∞ —Ç–æ–≤–∞—Ä–Ω—ã–µ –∑–Ω–∞–∫–∏
                    for text_item in img_check.get('recognized_texts', []):
                        if text_item.text and len(text_item.text) > 2:
                            tm_results = trademark_checker.check_all(
                                text_item.text, item.mktu_classes
                            )
                            item.trademark_results.extend(tm_results)

                    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                    item.image_search_results.extend(img_check.get('search_results', []))

                    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏ –∞–≤—Ç–æ—Ä—Å–∫–∏—Ö –ø—Ä–∞–≤
                    if img_check.get('copyright_result'):
                        item.copyright_results.append(img_check['copyright_result'])

            # –û—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–∞
            assessment = risk_evaluator.evaluate_product(item)
            assessments[item.article] = assessment

            # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å —Ç–æ–≤–∞—Ä–∞
            item.overall_status = assessment.overall_status
            item.status_reason = assessment.summary
            item.recommendations = assessment.recommendations
            item.checked_at = datetime.now()

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        session_data['assessments'] = assessments
        session.update_statistics()

        return jsonify({
            'success': True,
            'session_id': session_id,
            'statistics': {
                'total': session.total_items,
                'checked': session.checked_items,
                'red': session.red_count,
                'yellow': session.yellow_count,
                'green': session.green_count
            },
            'results': [
                {
                    'article': item.article,
                    'name': item.name,
                    'status': item.overall_status.value,
                    'risk_score': assessments[item.article].overall_score if item.article in assessments else 0,
                    'summary': item.status_reason,
                    'recommendations': item.recommendations[:3]
                }
                for item in session.items
            ]
        })

    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/session/<session_id>')
def get_session(session_id):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–µ—Å—Å–∏–∏"""
    if session_id not in sessions_store:
        return jsonify({'error': '–°–µ—Å—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'}), 404

    session_data = sessions_store[session_id]
    session = session_data['session']
    assessments = session_data.get('assessments', {})

    return jsonify({
        'session_id': session.session_id,
        'created_at': session.created_at.isoformat(),
        'statistics': {
            'total': session.total_items,
            'red': session.red_count,
            'yellow': session.yellow_count,
            'green': session.green_count
        },
        'items': [
            {
                'article': item.article,
                'name': item.name,
                'status': item.overall_status.value,
                'risk_score': assessments[item.article].overall_score if item.article in assessments else 0,
                'checked': item.checked_at is not None
            }
            for item in session.items
        ]
    })


@app.route('/api/export/<session_id>/<format>')
def export_results(session_id, format):
    """–≠–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    if session_id not in sessions_store:
        return jsonify({'error': '–°–µ—Å—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'}), 404

    session_data = sessions_store[session_id]
    session = session_data['session']
    assessments = session_data.get('assessments', {})

    try:
        if format == 'excel':
            filepath = export_manager.export_to_excel(session, assessments)
            return send_file(filepath, as_attachment=True)
        elif format == 'csv':
            filepath = export_manager.export_to_csv(session, assessments)
            return send_file(filepath, as_attachment=True)
        elif format == 'json':
            filepath = export_manager.export_to_json(session, assessments)
            return send_file(filepath, as_attachment=True)
        elif format == 'html':
            filepath = export_manager.export_to_html(session, assessments)
            return send_file(filepath, as_attachment=True)
        else:
            return jsonify({'error': '–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç'}), 400

    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/template')
def download_template():
    """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ —à–∞–±–ª–æ–Ω–∞ Excel"""
    try:
        filepath = TemplateGenerator.create_excel_template()
        return send_file(filepath, as_attachment=True)
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/resources')
def get_resources():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏"""
    return jsonify({
        'trademark_resources': TRADEMARK_RESOURCES,
        'image_resources': IMAGE_SEARCH_RESOURCES,
        'mktu_classes': MKTU_CLASSES
    })


@app.route('/api/check/links', methods=['POST'])
def get_check_links():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Å—ã–ª–æ–∫ –¥–ª—è —Ä—É—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏"""
    data = request.json
    text = data.get('text', '')
    mktu_classes = data.get('mktu_classes', [])

    links = trademark_checker.generate_manual_check_links(text, mktu_classes)

    return jsonify({
        'text': text,
        'links': links
    })


@app.route('/api/check/image', methods=['POST'])
def check_image_full():
    """
    –ü–æ–ª–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:
    1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    2. –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ (OCR)
    3. –ü–æ–∏—Å–∫ –ø–æ —Ç–æ–≤–∞—Ä–Ω—ã–º –∑–Ω–∞–∫–∞–º
    4. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Å—ã–ª–æ–∫ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
    """
    if 'file' not in request.files:
        return jsonify({'error': '–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω'}), 400

    file = request.files['file']
    if file.filename == '':
        return jsonify({'error': '–§–∞–π–ª –Ω–µ –≤—ã–±—Ä–∞–Ω'}), 400

    if not allowed_file(file.filename, APP_CONFIG['allowed_extensions']):
        return jsonify({'error': '–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞'}), 400

    try:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
        upload_dir = Path(app.config['UPLOAD_FOLDER']) / str(uuid.uuid4())[:8]
        upload_dir.mkdir(parents=True, exist_ok=True)

        from werkzeug.utils import secure_filename
        filename = secure_filename(file.filename)
        filepath = upload_dir / filename
        file.save(filepath)

        # –ü–æ–ª—É—á–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        mktu_classes = request.form.getlist('mktu_classes', type=int)
        manual_text = request.form.get('text', '').strip()

        # –†–µ–∑—É–ª—å—Ç–∞—Ç
        result = {
            'filename': filename,
            'filepath': str(filepath),
            'image_url': f'/uploads/{upload_dir.name}/{filename}',
            'recognized_texts': [],
            'trademark_results': [],
            'image_search_links': {},
            'overall_status': 'green',
            'risk_factors': [],
            'recommendations': [],
            'summary': ''
        }

        # 1. –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ (OCR)
        try:
            img_check = image_checker.check_image(str(filepath))

            # –ü–æ–ª—É—á–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (—Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ >= 55%)
            # –ù–ï –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–µ–Ω–∞–¥—ë–∂–Ω—ã–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è - –æ–Ω–∏ –¥–∞—é—Ç —Å–ª—É—á–∞–π–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            for text_item in img_check.get('recognized_texts', []):
                # –°—Ç—Ä–æ–≥–∏–π —Ñ–∏–ª—å—Ç—Ä: —Ç–æ–ª—å–∫–æ —É–≤–µ—Ä–µ–Ω–Ω—ã–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è (55%+)
                if text_item.confidence < 0.55:
                    continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–Ω–∞–¥—ë–∂–Ω—ã–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è

                text_clean = text_item.text.strip()
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –º—É—Å–æ—Ä–∞
                if len(text_clean) < 3:
                    continue
                if not any(c.isalpha() for c in text_clean):
                    continue

                result['recognized_texts'].append({
                    'text': text_clean,
                    'confidence': round(text_item.confidence * 100, 1)
                })

            # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –∞–≤—Ç–æ—Ä—Å–∫–∏—Ö –ø—Ä–∞–≤
            copyright_result = img_check.get('copyright_result')
            if copyright_result:
                if copyright_result.brand_elements:
                    result['risk_factors'].append({
                        'type': 'brand',
                        'severity': 'red',
                        'message': f"–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –±—Ä–µ–Ω–¥—ã: {', '.join(copyright_result.brand_elements)}"
                    })
                if copyright_result.character_names:
                    result['risk_factors'].append({
                        'type': 'character',
                        'severity': 'red',
                        'message': f"–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø–µ—Ä—Å–æ–Ω–∞–∂–∏: {', '.join(copyright_result.character_names)}"
                    })
        except Exception as e:
            result['recommendations'].append(f"–û—à–∏–±–∫–∞ OCR: {str(e)}")

        # 2. –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ –¢–ó
        texts_to_check = []
        texts_to_check_lower = set()  # –î–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏

        # –î–æ–±–∞–≤–ª—è–µ–º —Ä—É—á–Ω–æ–π —Ç–µ–∫—Å—Ç (–∏–º–µ–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
        if manual_text:
            texts_to_check.append(manual_text)
            texts_to_check_lower.add(manual_text.lower())

        # –î–æ–±–∞–≤–ª—è–µ–º –¢–û–õ–¨–ö–û —É–≤–µ—Ä–µ–Ω–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (–ø–æ—Ä–æ–≥ —É–∂–µ –ø—Ä–∏–º–µ–Ω—ë–Ω –≤—ã—à–µ)
        for text_item in result['recognized_texts']:
            full_text = text_item['text'].strip()

            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç —Ü–µ–ª–∏–∫–æ–º (–µ—Å–ª–∏ > 2 —Å–∏–º–≤–æ–ª–æ–≤)
            if len(full_text) > 2 and full_text.lower() not in texts_to_check_lower:
                texts_to_check.append(full_text)
                texts_to_check_lower.add(full_text.lower())

            # –¢–∞–∫–∂–µ –¥–æ–±–∞–≤–ª—è–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ (–µ—Å–ª–∏ > 2 —Å–∏–º–≤–æ–ª–æ–≤)
            words = full_text.split()
            for word in words:
                clean_word = ''.join(c for c in word if c.isalnum())
                if len(clean_word) > 2 and clean_word.lower() not in texts_to_check_lower:
                    texts_to_check.append(clean_word)
                    texts_to_check_lower.add(clean_word.lower())

        # 2.1. –î–µ—Ç–µ–∫—Ü–∏—è –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –±—Ä–µ–Ω–¥–æ–≤ –ø–æ –í–°–ï–ú —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∏—è–º (–≤–∫–ª—é—á–∞—è –Ω–∏–∑–∫–æ—É–≤–µ—Ä–µ–Ω–Ω—ã–µ)
        # –≠—Ç–æ –¥–ª—è –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è, –Ω–æ –ù–ï –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞ –¢–ó
        KNOWN_BRANDS_PATTERNS = {
            'nike': ['nike', 'nke', 'nik', 'nik–µ', 'ni–∫–µ', 'n—ñke', 'n1ke', 'nikel'],
            'adidas': ['adidas', 'adldas', 'ad—ñdas', 'ad1das'],
            'puma': ['puma', '—Äuma', 'pum–∞'],
            'gucci': ['gucci', 'gucc—ñ', 'gu—Åci'],
            'chanel': ['chanel', '—Åhanel', 'chan–µl'],
            'louis vuitton': ['vuitton', 'vu—ñtton', 'lv'],
            'supreme': ['supreme', 'supr–µme', 'supr–µm–µ'],
            'champion': ['champion', 'champ1on', '—Åhampion', 'champi0n', 'lkpio', 'ckpio', 'chpio'],
        }

        # –°–æ–±–∏—Ä–∞–µ–º –í–°–ï —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã (–≤–∫–ª—é—á–∞—è –Ω–∏–∑–∫–æ—É–≤–µ—Ä–µ–Ω–Ω—ã–µ) –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –±—Ä–µ–Ω–¥–æ–≤
        all_raw_texts = []
        for text_item in img_check.get('recognized_texts', []):
            if text_item.confidence > 0.15:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –±—Ä–µ–Ω–¥–æ–≤
                all_raw_texts.append(text_item.text.lower())
        all_recognized_text = ' '.join(all_raw_texts)

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–µ–∫—Å—Ç (–∑–∞–º–µ–Ω—è–µ–º –ø–æ—Ö–æ–∂–∏–µ —Å–∏–º–≤–æ–ª—ã)
        normalized_text = all_recognized_text.replace('–∫', 'k').replace('–µ', 'e').replace('—ñ', 'i').replace('–∞', 'a').replace('–æ', 'o').replace('—Å', 'c').replace('—Ä', 'p').replace('–≤', 'b')

        detected_brands = []
        for brand, patterns in KNOWN_BRANDS_PATTERNS.items():
            for pattern in patterns:
                if pattern in normalized_text or pattern in all_recognized_text:
                    detected_brands.append(brand.upper())
                    # –ù–ï –¥–æ–±–∞–≤–ª—è–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤ texts_to_check - –ø—Ä–æ—Å—Ç–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞–µ–º
                    result['risk_factors'].append({
                        'type': 'brand_detected',
                        'severity': 'yellow',  # –ñ—ë–ª—Ç—ã–π, —Ç.–∫. OCR –Ω–µ —É–≤–µ—Ä–µ–Ω
                        'message': f"‚ö†Ô∏è –í–æ–∑–º–æ–∂–Ω–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω –±—Ä–µ–Ω–¥: {brand.upper()} (OCR —Ä–∞—Å–ø–æ–∑–Ω–∞–ª: '{all_recognized_text[:30]}...'). –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –≤—Ä—É—á–Ω—É—é."
                    })
                    break

        # –ï—Å–ª–∏ —Ä—É—á–Ω–æ–π —Ç–µ–∫—Å—Ç –Ω–µ –≤–≤–µ–¥—ë–Ω –ò OCR –Ω–∏—á–µ–≥–æ —É–≤–µ—Ä–µ–Ω–Ω–æ–≥–æ –Ω–µ –Ω–∞—à—ë–ª
        if not texts_to_check and not manual_text:
            result['recommendations'].append(
                "‚ö†Ô∏è OCR –Ω–µ —Å–º–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏. "
                "–ï—Å–ª–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –µ—Å—Ç—å –Ω–∞–¥–ø–∏—Å–∏, –≤–≤–µ–¥–∏—Ç–µ –∏—Ö –≤—Ä—É—á–Ω—É—é –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ç–æ–≤–∞—Ä–Ω—ã—Ö –∑–Ω–∞–∫–æ–≤."
            )

        # 3. –ü–æ–∏—Å–∫ –ø–æ —Ç–æ–≤–∞—Ä–Ω—ã–º –∑–Ω–∞–∫–∞–º (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –Ω–∞–¥—ë–∂–Ω—ã–π —Ç–µ–∫—Å—Ç)
        all_tm_results = []
        checked_texts = []

        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ–∏—Å–∫ –¢–ó –µ—Å–ª–∏ –Ω–µ—Ç –Ω–∞–¥—ë–∂–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        if not texts_to_check:
            result['recommendations'].append(
                "‚ÑπÔ∏è –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–≤–∞—Ä–Ω—ã—Ö –∑–Ω–∞–∫–æ–≤ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ - –Ω–µ—Ç —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞. "
                "–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –≤—Ä—É—á–Ω—É—é, –µ—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ."
            )

        for text in texts_to_check[:5]:  # –ú–∞–∫—Å–∏–º—É–º 5 –ø—Ä–æ–≤–µ—Ä–æ–∫
            try:
                tm_results = trademark_checker.check_all(text, mktu_classes)
                checked_texts.append(text)

                for r in tm_results:
                    tm_entry = {
                        'text': text,
                        'resource': r.resource_name,
                        'status': r.status.value,
                        'exact_match': r.exact_match,
                        'similar_match': r.similar_match,
                        'similarity_score': r.similarity_score,
                        'notes': r.notes,
                        'matches': r.found_matches[:5]
                    }
                    all_tm_results.append(tm_entry)

                    # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∞–∫—Ç–æ—Ä—ã —Ä–∏—Å–∫–∞
                    if r.exact_match:
                        result['risk_factors'].append({
                            'type': 'trademark',
                            'severity': 'red',
                            'message': f"–¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –¢–ó –¥–ª—è '{text}': {r.notes}"
                        })
                    elif r.similar_match and r.similarity_score >= 0.8:
                        result['risk_factors'].append({
                            'type': 'trademark',
                            'severity': 'yellow',
                            'message': f"–ü–æ—Ö–æ–∂–∏–π –¢–ó –¥–ª—è '{text}' ({r.similarity_score:.0%}): {r.notes}"
                        })

            except Exception as e:
                result['recommendations'].append(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ '{text}': {str(e)}")

        result['trademark_results'] = all_tm_results
        result['checked_texts'] = checked_texts

        # 4. –°—Å—ã–ª–∫–∏ –¥–ª—è —Ä—É—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –¢–ó
        if checked_texts:
            result['trademark_links'] = trademark_checker.generate_manual_check_links(
                checked_texts[0], mktu_classes
            )

        # 5. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ API
        result['image_search_results'] = []
        result['image_search_links'] = {}

        try:
            # –í—ã–ø–æ–ª–Ω—è–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ Serper API
            search_results = image_searcher.search_all(str(filepath), use_api=True)

            for sr in search_results:
                search_result_data = {
                    'resource': sr.resource_name,
                    'url': sr.resource_url,
                    'status': sr.status.value if hasattr(sr.status, 'value') else str(sr.status),
                    'notes': sr.notes,
                    'total_results': sr.total_results,
                    'exact_matches': sr.exact_matches,
                    'similar_images': sr.similar_images[:5] if sr.similar_images else [],
                    'known_sources': sr.known_sources[:5] if sr.known_sources else []
                }
                result['image_search_results'].append(search_result_data)

                # –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è - –¥–æ–±–∞–≤–ª—è–µ–º –≤ —Ñ–∞–∫—Ç–æ—Ä—ã —Ä–∏—Å–∫–∞
                if sr.status == RiskLevel.RED:
                    result['risk_factors'].append({
                        'type': 'image_search',
                        'severity': 'red',
                        'message': f"üîç {sr.resource_name}: {sr.notes}"
                    })
                elif sr.status == RiskLevel.YELLOW and sr.total_results > 0:
                    result['risk_factors'].append({
                        'type': 'image_search',
                        'severity': 'yellow',
                        'message': f"üîç {sr.resource_name}: {sr.notes}"
                    })

        except Exception as e:
            error_msg = str(e)
            # –£–ª—É—á—à–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
            if 'Connection' in error_msg or 'timeout' in error_msg.lower():
                result['recommendations'].append(
                    "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–æ—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è). "
                    "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å—Å—ã–ª–∫–∏ –Ω–∏–∂–µ –¥–ª—è —Ä—É—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏."
                )
            else:
                result['recommendations'].append(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {error_msg}")

        # –°—Å—ã–ª–∫–∏ –¥–ª—è —Ä—É—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ (—Ä–µ–∑–µ—Ä–≤–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç)
        result['image_search_links'] = {
            'yandex': {
                'name': '–Ø–Ω–¥–µ–∫—Å.–ö–∞—Ä—Ç–∏–Ω–∫–∏',
                'url': 'https://yandex.ru/images/',
                'instruction': '–ù–∞–∂–º–∏—Ç–µ –Ω–∞ –∏–∫–æ–Ω–∫—É –∫–∞–º–µ—Ä—ã –∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ'
            },
            'google': {
                'name': 'Google Images',
                'url': 'https://images.google.com/',
                'instruction': '–ù–∞–∂–º–∏—Ç–µ –Ω–∞ –∏–∫–æ–Ω–∫—É –∫–∞–º–µ—Ä—ã –∏ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ'
            },
            'bing': {
                'name': 'Bing Visual Search',
                'url': 'https://www.bing.com/visualsearch',
                'instruction': '–ü–µ—Ä–µ—Ç–∞—â–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø–æ–∏—Å–∫–∞'
            }
        }

        # 6. –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±—â–∏–π —Å—Ç–∞—Ç—É—Å
        has_red = any(f['severity'] == 'red' for f in result['risk_factors'])
        has_yellow = any(f['severity'] == 'yellow' for f in result['risk_factors'])
        has_tm_red = any(r['status'] == 'red' for r in all_tm_results)
        has_tm_yellow = any(r['status'] == 'yellow' for r in all_tm_results)

        if has_red or has_tm_red:
            result['overall_status'] = 'red'
        elif has_yellow or has_tm_yellow:
            result['overall_status'] = 'yellow'
        else:
            result['overall_status'] = 'green'

        # 7. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if result['overall_status'] == 'red':
            result['recommendations'].insert(0,
                "‚õî –í–ù–ò–ú–ê–ù–ò–ï: –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –±–µ–∑ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ —é—Ä–∏—Å—Ç–∞."
            )
        elif result['overall_status'] == 'yellow':
            result['recommendations'].insert(0,
                "‚ö†Ô∏è –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º."
            )
        else:
            result['recommendations'].insert(0,
                "‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ –≤—ã—è–≤–∏–ª–∞ —è–≤–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º."
            )

        if not result['recognized_texts']:
            result['recommendations'].append(
                "–¢–µ–∫—Å—Ç –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω. –ï—Å–ª–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –µ–≥–æ –≤—Ä—É—á–Ω—É—é."
            )

        result['recommendations'].append(
            "–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –≤—ã–ø–æ–ª–Ω–∏—Ç—å –æ–±—Ä–∞—Ç–Ω—ã–π –ø–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ —Å—Å—ã–ª–∫–∞–º –Ω–∏–∂–µ."
        )

        # 8. –°–≤–æ–¥–∫–∞
        result['summary'] = {
            'texts_found': len(result['recognized_texts']),
            'texts_checked': len(checked_texts),
            'tm_checks': len(all_tm_results),
            'risk_factors_count': len(result['risk_factors'])
        }

        # 9. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
        try:
            check_id = save_image_check(
                filename=filename,
                filepath=str(filepath),
                overall_status=result['overall_status'],
                recognized_texts=result['recognized_texts'],
                trademark_results=result['trademark_results'],
                image_search_results=result.get('image_search_results', []),
                risk_factors=result['risk_factors'],
                recommendations=result['recommendations'],
                summary=result['summary']
            )
            result['check_id'] = check_id
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –∏—Å—Ç–æ—Ä–∏—é: {e}")

        return jsonify(result)

    except Exception as e:
        import traceback
        return jsonify({
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500


@app.route('/uploads/<path:filename>')
def serve_upload(filename):
    """–û—Ç–¥–∞—á–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
    return send_file(Path(app.config['UPLOAD_FOLDER']) / filename)


# ==================== –ò–°–¢–û–†–ò–Ø –ü–†–û–í–ï–†–û–ö ====================

@app.route('/history')
def history_page():
    """–°—Ç—Ä–∞–Ω–∏—Ü–∞ –∏—Å—Ç–æ—Ä–∏–∏ –ø—Ä–æ–≤–µ—Ä–æ–∫"""
    return render_template('history.html',
                          mktu_classes=MKTU_CLASSES,
                          trademark_resources=TRADEMARK_RESOURCES,
                          image_resources=IMAGE_SEARCH_RESOURCES)


@app.route('/api/history/stats')
def get_history_stats():
    """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ–≤–µ—Ä–æ–∫"""
    try:
        stats = get_statistics()
        return jsonify(stats)
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/history/names')
def get_name_history():
    """–ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–æ–≤–µ—Ä–æ–∫ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–π"""
    try:
        limit = request.args.get('limit', 50, type=int)
        offset = request.args.get('offset', 0, type=int)
        status = request.args.get('status', None)

        checks = get_name_checks(limit=limit, offset=offset, status_filter=status)
        return jsonify({'checks': checks})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/history/images')
def get_image_history():
    """–ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–æ–≤–µ—Ä–æ–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
    try:
        limit = request.args.get('limit', 50, type=int)
        offset = request.args.get('offset', 0, type=int)
        status = request.args.get('status', None)

        checks = get_image_checks(limit=limit, offset=offset, status_filter=status)
        return jsonify({'checks': checks})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/history/name/<int:check_id>')
def get_name_check_detail(check_id):
    """–ü–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è"""
    try:
        check = get_name_check_by_id(check_id)
        if not check:
            return jsonify({'error': '–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'}), 404
        return jsonify(check)
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/history/image/<int:check_id>')
def get_image_check_detail(check_id):
    """–ü–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    try:
        check = get_image_check_by_id(check_id)
        if not check:
            return jsonify({'error': '–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'}), 404
        return jsonify(check)
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/history/delete/<check_type>/<int:check_id>', methods=['DELETE'])
def delete_history_check(check_type, check_id):
    """–£–¥–∞–ª–∏—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏"""
    try:
        if check_type not in ['name', 'image']:
            return jsonify({'error': '–ù–µ–≤–µ—Ä–Ω—ã–π —Ç–∏–ø –ø—Ä–æ–≤–µ—Ä–∫–∏'}), 400

        success = delete_check(check_type, check_id)
        if success:
            return jsonify({'success': True})
        return jsonify({'error': '–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'}), 404
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/history/clear', methods=['DELETE'])
def clear_all_history():
    """–û—á–∏—Å—Ç–∏—Ç—å –≤—Å—é –∏—Å—Ç–æ—Ä–∏—é"""
    try:
        check_type = request.args.get('type', None)
        deleted = clear_history(check_type)
        return jsonify({'success': True, 'deleted': deleted})
    except Exception as e:
        return jsonify({'error': str(e)}), 500


# ==================== –≠–ö–°–ü–û–†–¢ –û–¢–ß–Å–¢–û–í ====================

@app.route('/api/export/image/<int:check_id>/<format>')
def export_image_report(check_id, format):
    """–≠–∫—Å–ø–æ—Ä—Ç –æ—Ç—á—ë—Ç–∞ –ø–æ –ø—Ä–æ–≤–µ—Ä–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    try:
        check = get_image_check_by_id(check_id)
        if not check:
            return jsonify({'error': '–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'}), 404

        if format == 'excel':
            filepath = export_image_to_excel(check)
            return send_file(filepath, as_attachment=True,
                           download_name=f"report_image_{check_id}.xlsx")
        elif format == 'pdf':
            filepath = export_image_to_pdf(check)
            return send_file(filepath, as_attachment=True,
                           download_name=f"report_image_{check_id}.pdf")
        elif format == 'json':
            return jsonify(check)
        else:
            return jsonify({'error': '–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç'}), 400

    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/export/name/<int:check_id>/<format>')
def export_name_report(check_id, format):
    """–≠–∫—Å–ø–æ—Ä—Ç –æ—Ç—á—ë—Ç–∞ –ø–æ –ø—Ä–æ–≤–µ—Ä–∫–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è"""
    try:
        check = get_name_check_by_id(check_id)
        if not check:
            return jsonify({'error': '–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞'}), 404

        if format == 'excel':
            filepath = export_name_to_excel(check)
            return send_file(filepath, as_attachment=True,
                           download_name=f"report_name_{check_id}.xlsx")
        elif format == 'pdf':
            filepath = export_name_to_pdf(check)
            return send_file(filepath, as_attachment=True,
                           download_name=f"report_name_{check_id}.pdf")
        elif format == 'json':
            return jsonify(check)
        else:
            return jsonify({'error': '–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç'}), 400

    except Exception as e:
        return jsonify({'error': str(e)}), 500


def export_image_to_excel(check: Dict) -> str:
    """–≠–∫—Å–ø–æ—Ä—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ Excel"""
    import openpyxl
    from openpyxl.styles import Font, PatternFill, Alignment, Border, Side

    wb = openpyxl.Workbook()
    ws = wb.active
    ws.title = "–û—Ç—á—ë—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏"

    # –°—Ç–∏–ª–∏
    header_font = Font(bold=True, size=14)
    status_fills = {
        'red': PatternFill(start_color="FF6B6B", end_color="FF6B6B", fill_type="solid"),
        'yellow': PatternFill(start_color="FFE66D", end_color="FFE66D", fill_type="solid"),
        'green': PatternFill(start_color="6BCB77", end_color="6BCB77", fill_type="solid")
    }

    row = 1

    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    ws.cell(row=row, column=1, value="–û–¢–ß–Å–¢ –û –ü–†–û–í–ï–†–ö–ï –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø").font = Font(bold=True, size=16)
    row += 2

    # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    ws.cell(row=row, column=1, value="–§–∞–π–ª:").font = header_font
    ws.cell(row=row, column=2, value=check.get('filename', '-'))
    row += 1

    ws.cell(row=row, column=1, value="–î–∞—Ç–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏:").font = header_font
    ws.cell(row=row, column=2, value=check.get('created_at', '-'))
    row += 1

    ws.cell(row=row, column=1, value="–°—Ç–∞—Ç—É—Å:").font = header_font
    status = check.get('overall_status', 'green')
    status_text = {'red': '–ó–ê–ü–†–ï–©–ï–ù–û', 'yellow': '–¢–†–ï–ë–£–ï–¢ –ü–†–û–í–ï–†–ö–ò', 'green': '–†–ê–ó–†–ï–®–ï–ù–û'}.get(status, status)
    cell = ws.cell(row=row, column=2, value=status_text)
    cell.fill = status_fills.get(status, status_fills['green'])
    row += 2

    # –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã
    ws.cell(row=row, column=1, value="–†–ê–°–ü–û–ó–ù–ê–ù–ù–´–ï –¢–ï–ö–°–¢–´").font = header_font
    row += 1
    texts = check.get('recognized_texts', [])
    if texts:
        for t in texts:
            ws.cell(row=row, column=1, value=t.get('text', '-'))
            ws.cell(row=row, column=2, value=f"{t.get('confidence', 0)}%")
            row += 1
    else:
        ws.cell(row=row, column=1, value="–¢–µ–∫—Å—Ç –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω")
        row += 1
    row += 1

    # –§–∞–∫—Ç–æ—Ä—ã —Ä–∏—Å–∫–∞
    ws.cell(row=row, column=1, value="–§–ê–ö–¢–û–†–´ –†–ò–°–ö–ê").font = header_font
    row += 1
    risks = check.get('risk_factors', [])
    if risks:
        for r in risks:
            ws.cell(row=row, column=1, value=r.get('message', '-'))
            row += 1
    else:
        ws.cell(row=row, column=1, value="–ù–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
        row += 1
    row += 1

    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    ws.cell(row=row, column=1, value="–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò").font = header_font
    row += 1
    recs = check.get('recommendations', [])
    for r in recs:
        ws.cell(row=row, column=1, value=r)
        row += 1

    # –ê–≤—Ç–æ—à–∏—Ä–∏–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫
    ws.column_dimensions['A'].width = 40
    ws.column_dimensions['B'].width = 50

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    output_path = OUTPUT_DIR / f"report_image_{check.get('id', 'unknown')}.xlsx"
    wb.save(str(output_path))
    return str(output_path)


def export_image_to_pdf(check: Dict) -> str:
    """–≠–∫—Å–ø–æ—Ä—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ PDF"""
    from reportlab.lib import colors
    from reportlab.lib.pagesizes import A4
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.lib.units import cm
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
    from reportlab.pdfbase import pdfmetrics
    from reportlab.pdfbase.ttfonts import TTFont

    # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º —à—Ä–∏—Ñ—Ç —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∫–∏—Ä–∏–ª–ª–∏—Ü—ã
    try:
        pdfmetrics.registerFont(TTFont('DejaVu', '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf'))
        font_name = 'DejaVu'
    except:
        font_name = 'Helvetica'

    output_path = OUTPUT_DIR / f"report_image_{check.get('id', 'unknown')}.pdf"
    doc = SimpleDocTemplate(str(output_path), pagesize=A4,
                           rightMargin=2*cm, leftMargin=2*cm,
                           topMargin=2*cm, bottomMargin=2*cm)

    styles = getSampleStyleSheet()
    styles.add(ParagraphStyle(name='RuTitle', fontName=font_name, fontSize=18, spaceAfter=20))
    styles.add(ParagraphStyle(name='RuHeading', fontName=font_name, fontSize=14, spaceAfter=10, spaceBefore=15))
    styles.add(ParagraphStyle(name='RuNormal', fontName=font_name, fontSize=11, spaceAfter=5))

    story = []

    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    story.append(Paragraph("OTCHET O PROVERKE IZOBRAZHENIYA", styles['RuTitle']))
    story.append(Spacer(1, 0.5*cm))

    # –°—Ç–∞—Ç—É—Å
    status = check.get('overall_status', 'green')
    status_text = {'red': 'ZAPRESHCHENO', 'yellow': 'TREBUET PROVERKI', 'green': 'RAZRESHENO'}.get(status, status)
    status_color = {'red': colors.red, 'yellow': colors.yellow, 'green': colors.green}.get(status, colors.green)

    # –û—Å–Ω–æ–≤–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    data = [
        ['Fayl:', check.get('filename', '-')],
        ['Data:', check.get('created_at', '-')],
        ['Status:', status_text],
    ]
    t = Table(data, colWidths=[4*cm, 12*cm])
    t.setStyle(TableStyle([
        ('FONTNAME', (0, 0), (-1, -1), font_name),
        ('FONTSIZE', (0, 0), (-1, -1), 11),
        ('FONTNAME', (0, 0), (0, -1), font_name),
        ('BACKGROUND', (1, 2), (1, 2), status_color),
    ]))
    story.append(t)
    story.append(Spacer(1, 0.5*cm))

    # –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã
    story.append(Paragraph("Raspoznannye teksty:", styles['RuHeading']))
    texts = check.get('recognized_texts', [])
    if texts:
        for t in texts:
            story.append(Paragraph(f"‚Ä¢ {t.get('text', '-')} ({t.get('confidence', 0)}%)", styles['RuNormal']))
    else:
        story.append(Paragraph("Tekst ne raspoznan", styles['RuNormal']))

    # –§–∞–∫—Ç–æ—Ä—ã —Ä–∏—Å–∫–∞
    story.append(Paragraph("Faktory riska:", styles['RuHeading']))
    risks = check.get('risk_factors', [])
    if risks:
        for r in risks:
            story.append(Paragraph(f"‚Ä¢ {r.get('message', '-')}", styles['RuNormal']))
    else:
        story.append(Paragraph("Ne obnaruzheno", styles['RuNormal']))

    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    story.append(Paragraph("Rekomendatsii:", styles['RuHeading']))
    recs = check.get('recommendations', [])
    for r in recs:
        # –£–±–∏—Ä–∞–µ–º —ç–º–æ–¥–∑–∏ –¥–ª—è PDF
        r_clean = r.replace('‚õî', '[!]').replace('‚ö†Ô∏è', '[!]').replace('‚úÖ', '[OK]')
        story.append(Paragraph(f"‚Ä¢ {r_clean}", styles['RuNormal']))

    doc.build(story)
    return str(output_path)


def export_name_to_excel(check: Dict) -> str:
    """–≠–∫—Å–ø–æ—Ä—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è –≤ Excel"""
    import openpyxl
    from openpyxl.styles import Font, PatternFill

    wb = openpyxl.Workbook()
    ws = wb.active
    ws.title = "–û—Ç—á—ë—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏"

    header_font = Font(bold=True, size=14)
    status_fills = {
        'red': PatternFill(start_color="FF6B6B", end_color="FF6B6B", fill_type="solid"),
        'yellow': PatternFill(start_color="FFE66D", end_color="FFE66D", fill_type="solid"),
        'green': PatternFill(start_color="6BCB77", end_color="6BCB77", fill_type="solid")
    }

    row = 1

    ws.cell(row=row, column=1, value="–û–¢–ß–Å–¢ –û –ü–†–û–í–ï–†–ö–ï –ù–ê–ò–ú–ï–ù–û–í–ê–ù–ò–Ø").font = Font(bold=True, size=16)
    row += 2

    ws.cell(row=row, column=1, value="–¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞:").font = header_font
    ws.cell(row=row, column=2, value=check.get('query_text', '-'))
    row += 1

    ws.cell(row=row, column=1, value="–ö–ª–∞—Å—Å—ã –ú–ö–¢–£:").font = header_font
    ws.cell(row=row, column=2, value=', '.join(map(str, check.get('mktu_classes', []))) or '-')
    row += 1

    ws.cell(row=row, column=1, value="–î–∞—Ç–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏:").font = header_font
    ws.cell(row=row, column=2, value=check.get('created_at', '-'))
    row += 1

    ws.cell(row=row, column=1, value="–°—Ç–∞—Ç—É—Å:").font = header_font
    status = check.get('overall_status', 'green')
    status_text = {'red': '–ó–ê–ü–†–ï–©–ï–ù–û', 'yellow': '–¢–†–ï–ë–£–ï–¢ –ü–†–û–í–ï–†–ö–ò', 'green': '–†–ê–ó–†–ï–®–ï–ù–û'}.get(status, status)
    cell = ws.cell(row=row, column=2, value=status_text)
    cell.fill = status_fills.get(status, status_fills['green'])
    row += 2

    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏
    ws.cell(row=row, column=1, value="–†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–†–û–í–ï–†–ö–ò").font = header_font
    row += 1
    results = check.get('results', [])
    for r in results:
        ws.cell(row=row, column=1, value=r.get('resource', '-'))
        ws.cell(row=row, column=2, value=r.get('notes', '-'))
        row += 1
    row += 1

    # –°—Å—ã–ª–∫–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
    ws.cell(row=row, column=1, value="–°–°–´–õ–ö–ò –î–õ–Ø –†–£–ß–ù–û–ô –ü–†–û–í–ï–†–ö–ò").font = header_font
    row += 1
    links = check.get('manual_links', {})
    for name, url in links.items():
        ws.cell(row=row, column=1, value=name)
        ws.cell(row=row, column=2, value=url)
        row += 1

    ws.column_dimensions['A'].width = 40
    ws.column_dimensions['B'].width = 60

    output_path = OUTPUT_DIR / f"report_name_{check.get('id', 'unknown')}.xlsx"
    wb.save(str(output_path))
    return str(output_path)


def export_name_to_pdf(check: Dict) -> str:
    """–≠–∫—Å–ø–æ—Ä—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è –≤ PDF"""
    from reportlab.lib import colors
    from reportlab.lib.pagesizes import A4
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.lib.units import cm
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
    from reportlab.pdfbase import pdfmetrics
    from reportlab.pdfbase.ttfonts import TTFont

    try:
        pdfmetrics.registerFont(TTFont('DejaVu', '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf'))
        font_name = 'DejaVu'
    except:
        font_name = 'Helvetica'

    output_path = OUTPUT_DIR / f"report_name_{check.get('id', 'unknown')}.pdf"
    doc = SimpleDocTemplate(str(output_path), pagesize=A4,
                           rightMargin=2*cm, leftMargin=2*cm,
                           topMargin=2*cm, bottomMargin=2*cm)

    styles = getSampleStyleSheet()
    styles.add(ParagraphStyle(name='RuTitle', fontName=font_name, fontSize=18, spaceAfter=20))
    styles.add(ParagraphStyle(name='RuHeading', fontName=font_name, fontSize=14, spaceAfter=10, spaceBefore=15))
    styles.add(ParagraphStyle(name='RuNormal', fontName=font_name, fontSize=11, spaceAfter=5))

    story = []

    story.append(Paragraph("OTCHET O PROVERKE NAIMENOVANIYA", styles['RuTitle']))
    story.append(Spacer(1, 0.5*cm))

    status = check.get('overall_status', 'green')
    status_text = {'red': 'ZAPRESHCHENO', 'yellow': 'TREBUET PROVERKI', 'green': 'RAZRESHENO'}.get(status, status)
    status_color = {'red': colors.red, 'yellow': colors.yellow, 'green': colors.green}.get(status, colors.green)

    data = [
        ['Tekst:', check.get('query_text', '-')],
        ['Klassy MKTU:', ', '.join(map(str, check.get('mktu_classes', []))) or '-'],
        ['Data:', check.get('created_at', '-')],
        ['Status:', status_text],
    ]
    t = Table(data, colWidths=[4*cm, 12*cm])
    t.setStyle(TableStyle([
        ('FONTNAME', (0, 0), (-1, -1), font_name),
        ('FONTSIZE', (0, 0), (-1, -1), 11),
        ('BACKGROUND', (1, 3), (1, 3), status_color),
    ]))
    story.append(t)
    story.append(Spacer(1, 0.5*cm))

    story.append(Paragraph("Rezultaty proverki:", styles['RuHeading']))
    results = check.get('results', [])
    for r in results:
        story.append(Paragraph(f"‚Ä¢ {r.get('resource', '-')}: {r.get('notes', '-')}", styles['RuNormal']))

    story.append(Paragraph("Ssylki dlya proverki:", styles['RuHeading']))
    links = check.get('manual_links', {})
    for name, url in links.items():
        story.append(Paragraph(f"‚Ä¢ {name}: {url}", styles['RuNormal']))

    doc.build(story)
    return str(output_path)


if __name__ == '__main__':
    print("=" * 60)
    print("–°–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–π —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏")
    print("=" * 60)
    print(f"–ó–∞–ø—É—Å–∫ –≤–µ–±-—Å–µ—Ä–≤–µ—Ä–∞ –Ω–∞ http://localhost:{APP_CONFIG['port']}")
    print("–î–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–∞–∂–º–∏—Ç–µ Ctrl+C")
    print("=" * 60)

    app.run(
        host=APP_CONFIG['host'],
        port=APP_CONFIG['port'],
        debug=APP_CONFIG['debug']
    )
